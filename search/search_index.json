{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Semantic UBEM construction","text":""},{"location":"#introduction","title":"Introduction","text":"<p>The methodology presented aims to automate the generation of urban building energy models by leveraging Geographic Information Systems (GIS) data to construct individual energy models for each building. This system provides a structured approach to map GIS metadata fields to energy modeling components, thereby streamlining the energy modeling process for state-, national-, and global-scale analyses. Unlike traditional UBEM template archetype approaches, the key innovation lies in avoiding the need for energy modelers to manually create full-factorial combinations of building templates. Instead, it enables them to develop a library of individual components and define mapping rules that automatically select appropriate components based on building-specific metadata. This approach maintains a separation of concerns between the semantic information which lives in the GIS data (e.g. \"woodframe construction\" or \"high-income household\"), and the interpretation of that data as it is compiled into an energy model. It also enables flexibility by providing mechanisms for dealing with incomplete or incrementally updated data as well as probabilistic modeling. It also provides an easy mechanism for running different types of analysis on the same underlying GIS data, for instance running the data through a black-box simulation engine for rapid monthly energy estimation and then separately through a white-box simulation engine with an entirely different set of modeling inputs for a detailed overheating analysis.</p>"},{"location":"#system-overview","title":"System overview","text":"<p>The system operates by interpreting a manifest (specification file) that outlines how GIS metadata fields correspond to energy modeling components. The manifest is defined in YAML to emphasize human readiability and accessible editing. The manifest is divided into three primary sections:</p> <ol> <li>requires: Specifies the required metadata fields, their data types, allowable ranges or enumerations, and default values. Can be used to validate compatibility with incoming GIS data.</li> <li>computes: Defines computed fields derived from existing metadata, allowing for grouping or breakpointing of data to create new variables which can be referenced in the component map.</li> <li>component-map: Establishes the mapping rules that determine which energy modeling components (or values) are selected based on the provided and computed fields.</li> </ol> <p>Energy modeling engines can use a manifest to systematically interpret semantic GIS metadata and compile specific energy models, ensuring flexibility, consistency and scalability in large-scale bottom-up energy modeling.</p>"},{"location":"#manifest-schema","title":"Manifest schema","text":""},{"location":"#example-manifest","title":"Example manifest","text":"<p>An example manifest which defines each of the sections mentioned above is provided below. Subsequent sections will discuss each part of the manifest in more detail.</p> <pre><code>massachusetts:\n  requires:\n    year_built:\n      numeric:\n        min: 1620\n        max: 2024\n        integer: true\n      missing:\n        default: 1980\n\n    typology:\n      enum:\n        - single-family\n        - multi-family\n        - commercial\n        - industrial\n        - institutional\n        - mixed-use\n      missing:\n        skip:\n\n    construction:\n      enum:\n        - wood\n        - masonry\n        - concrete\n        - steel\n      missing:\n        fail:\n\n  computes:\n    year_bracket:\n      source: year_built\n      breakpoints:\n        - 1975\n        - 2003\n\n    typology_family:\n      source: typology\n      groups:\n        SFH:\n          - single-family\n        MFH:\n          - multi-family\n        CM:\n          - commercial\n          - industrial\n          - institutional\n          - mixed-use\n\n  component-map:\n    space_use:\n      base: typology_family\n    envelope:\n      base:\n        - typology_family\n        - construction\n        - year_bracket\n</code></pre>"},{"location":"#the-requires-section-defining-gis-metadata-expectations","title":"The <code>requires</code> section: defining GIS metadata expectations","text":"<p>The <code>requires</code> section enumerates the essential metadata fields that should be present for each building in the GIS dataset. Each field is specified with the following attributes:</p> <ul> <li>Data Type: Indicates whether the field is numeric or categorical (enum).</li> <li>Validation Constraints:</li> <li>For numeric fields: <code>min</code> and <code>max</code> values to ensure data validity.</li> <li>For enum fields: A list of acceptable categorical values.</li> <li>Missing Data Handler: Specifies a default value to be used if the field is missing or falls outside the valid range, or whether to skip a buiding or fail entirely.</li> </ul> <p>Example from a manifest:</p> <pre><code>requires:\n  year_built:\n    numeric:\n      min: 1620\n      max: 2024\n    missing:\n      default: 1980\n\n  typology:\n    enum:\n      - single-family\n      - multi-family\n      - commercial\n      - industrial\n      - mixed-use\n    missing:\n      skip:\n</code></pre> <p>This indicates that <code>year_built</code> is a required numeric field with valid years ranging from 1620 to 2024. If a building lacks this data, a default value of 1980 is assigned. Similarly, it indicates that a <code>typology</code> field should be provided in the GIS data, and if a value is missing, that building should be skipped entirely.</p>"},{"location":"#the-computes-section-deriving-new-tags","title":"The <code>computes</code> section: deriving new tags","text":"<p>The <code>computes</code> section allows for the creation of new fields based on transformations or groupings of existing metadata fields. This is particularly useful for categorizing continuous variables or aggregating multiple categories into broader groups.</p> <ul> <li>Breakpoints: Used to segment numeric fields into ranges.</li> <li>Groups: Used to aggregate categorical variables into higher-level categories.</li> </ul> <p>Example from a manifest:</p> <pre><code>computes:\n  year_bracket:\n    source: year_built\n    breakpoints:\n      - 1975\n      - 2003\n  typology_family:\n    source: typology\n    groups:\n      residential:\n        - single-family\n        - multi-family\n      non-residential:\n        - commercial\n        - industrial\n        - mixed-use\n</code></pre> <p>This computes a <code>year_bracket</code> field by segmenting <code>year_built</code> into ranges based on the specified breakpoints (before 1975, 1975-2003, after 2003). Similarly, it groups up multiple different values of the <code>typology</code> enum field into coarser groups.</p>"},{"location":"#the-component-map-section-defining-component-assignment-rules","title":"The <code>component-map</code> section: defining component assignment rules","text":"<p>The <code>component-map</code> section defines how energy modeling components should be selected based on one or more metadata fields, which can be either <code>required</code> fields directly provided by the GIS data or <code>computed</code> fields derived accordingly, or a mixture. Each energy model component (e.g., <code>space_use</code>, <code>envelope</code>) is associated with one or more fields that determine its selection. Additionally, for more granular control, specific values can be injected (e.g. for updating an Equipment Power Density within a previously selected component).</p> <ul> <li>Base Fields: The fields used to select the corresponding component.</li> <li>Naming Convention: Components are named based on the values of the base fields, concatenated with underscores.</li> </ul> <p>Example from a manifest:</p> <pre><code>space_use:\n  base: typology_family\nenvelope:\n  base:\n    - typology_family\n    - construction\n    - year_bracket\n</code></pre> <p>For <code>space_use</code>, the system will select a component matching the value of <code>typology_family</code>. For <code>envelope</code>, it will look for a component named by concatenating <code>typology_family</code>, <code>construction</code>, and <code>year_built</code> values, e.g. <code>residential_wood_pre1975</code>.</p>"},{"location":"#operational-workflow","title":"Operational workflow","text":"<p>For each building in the GIS dataset, the system follows these steps:</p> <ol> <li> <p>Validation and Default Assignment:</p> </li> <li> <p>Check that all required fields are present and valid.</p> </li> <li> <p>Assign default values where data is missing or invalid.</p> </li> <li> <p>Computed Field Generation:</p> </li> <li> <p>Compute new fields as specified in the <code>computes</code> section.</p> </li> <li> <p>Apply breakpoints and groupings to derive new categorical variables.</p> </li> <li> <p>Component Selection:</p> </li> <li>Use the <code>component-map</code> rules to determine the appropriate energy modeling components.</li> <li>Construct component names by concatenating the values of the base fields when needed.</li> <li>Retrieve the corresponding components from the library.</li> <li>Dynamically inject specific values when requested for leaf parameters (e.g. Equipment Power Density)</li> </ol>"},{"location":"#example-process-for-a-single-building","title":"Example process for a single building","text":"<ul> <li> <p>Metadata:</p> </li> <li> <p><code>year_built</code>: 1990</p> </li> <li><code>typology</code>: <code>commercial</code></li> <li> <p><code>construction</code>: <code>steel</code></p> </li> <li> <p>Processing:</p> </li> <li>Validation:<ul> <li>All required fields are present and valid.</li> </ul> </li> <li>Computed Fields:<ul> <li><code>year_bracket</code>: Since 1990 is between 1975 and 2003, <code>year_bracket</code> is set to the middle bracket, <code>1975to2003</code>.</li> <li><code>typology_family</code>: <code>typology</code> of <code>commercial</code> maps to <code>non-residential</code>.</li> </ul> </li> <li>Component Mapping:<ul> <li><code>space_use</code>: Will search for a <code>space_use</code> component called <code>non-residential</code>.</li> <li><code>envelope</code>: Combine <code>typology_family</code> (<code>non-residential</code>), <code>construction</code> (<code>steel</code>), and <code>year_bracket</code> (<code>1975to2003</code>) to form the component name <code>non-residential_steel_1975to2003</code>. Select the corresponding envelope component.</li> </ul> </li> </ul>"},{"location":"outline/","title":"Semantic Stock Modeling: Towards a Global Building Inventory","text":""},{"location":"outline/#abstract","title":"Abstract","text":"<p>Lorem ipsum</p>"},{"location":"outline/#introduction","title":"Introduction","text":"<p>TODO:</p> <ol> <li>Urgency of decarbonization</li> <li>Intersection of policy, economics, retrofitting rates: carbon, energy, and cost reduction are typically aligned, but not always - and equity is often orthogonal</li> <li>Quick overview of existing approaches with templates, bottom up, top-down</li> <li>segue into problems with traditional approaches</li> </ol> <p>Urban building energy modeling traditionally has relied on the law of large numbers to generate urban-scale insight: underlying archetypal energy models are assumed to be unbiased such that individual energy modeling errors at the building-scale destructively interfere to result in sufficient accuracy at the aggregated urban-scale, given a sufficient quantity of buildings within each archetypal class. On the one hand, this is a form of regularization, but on the other, it is a wasted opportunity. Although UBEMs are bottom-up, they still fail to deliver actionable information at the building scale. This leaves UBEMs with unfulfilled potential: every building is modeled, but no building is right. If compute is going to be spent, it ought to be fully leveraged to yield the most information it can. The most obvious use-case for building-scale accuracy in large urban datasets is in triaging the building stock to identify not just which types of buildings are best targeted with an intervention or policy measure, but which actual buildings should be targeted.</p> <p>At the same time as an increase in granularity is desired, an increase in scale is sought: how do we move from the urban-scale to the state/province-scale, the national-scale, and even the global-scale? While superficially, the goals of building-scale accuracy and superurban-scale data might seem opposed, many of the barriers - and thus solutions - to delivering both are shared. In both cases, one of the key challenges arises from the combination of data availability (or lack thereof) in conjunction with the curse of dimensionality. On the one hand, to get building-scale accuracy, more and more dimensions are needed to accurately capture the differences between each building and its neighbor, and thus an explosion in the full-factorial combinatoric possibilities which each require unique archetypal energy model templates. Similarly, as more and more geographic regions are covered, more possible values exist wihin each dimension (e.g. different residential envelope constructions in each region), which similarly induces a significant increase in the modeling complexity to create the necessary templates. This is exacerbated by varying degrees of data-availability: many buildings, or even whole regions, may have incomplete data available. For instance, the heating system of a building may be completely unknown, which can have a large impact on the economics of a retrofit adoption incentivization strategy, as dicussed in the case study in this paper. Similarly, only distributional information about a certain feature may be known, e.g. income level of the homeowner based off of census data. This scenario of incomplete or probabilistic data does not have a clear resolution in a framework where a single building is assumed to be associated with a single prototypical archetype energy model template.</p> <p>Another related major challenge that affects both building-scale accuracy and global-scale reach is data fusion: there is no authoritative source of truth on the state of the building stock in any one region, let alone across the world. Any such effort would necessarily require integrating a patchwork of GIS datasets. For instance, a model might consume from public datasets to extract fields like geometry and height for generating 2.5D building footprint based models, while consuming private or state-supplied tax parcel databases for information like building usage or age, and then consuming state-of-the-art research datasets for fields like computer-vision-extracted window-to-wall ratios. Deciding how to fuse these datasets, segment them into archetypes, and then create archetypal energy model templates for each segmented class is a non-trivial task. Furthermore, different regions may require entirely different energy models, with no universal isotropic building energy model which is applicable to the entire building stock achievable: the correct way to model a suburban home in Western Massachusetts might be drastically different from the correct way to model a commercial building in London or a naturally ventilated apartment building in Morocco.</p> <p>The scope also necessarily requires integrating multiple stakeholders, none of whom necessarily have all of the knowledge, skills or data at hand necessary to complete the pipeline. GIS managers may have the data representing the building stock, but insufficient knowledge of what is relevant to the building energy modeling effort (or another analysis modality). Energy modelers may have a good sense of what each of the different energy models ought to look like given a particular building description, but not the ability to programmatically generate or execute them all. Research software engineers may have the skillset to programmatically generate templates or to orchestrate the execution of models, but not the requisite knowledge for how to interpret a given row of GIS data into a particular energy model.</p> <p>To address these challenges attendant to building-scale accuracy and national-to-global reach, we propose a new approach to representing and organizing large datasets of real-world buildings: Semantic Stock Modeling (SSM). The key paradigm shift vis-a-vis traditional UBEMs is to dispose of the notion of archetypes, i.e. the association of a prototypical, pre-defined (excluding geometry) energy model with each building, and instead adopt a new organizational framework which consists of semantic building descriptions (which are agnostic as to their computational representation), paired with translation layers which interpret the semantics and compile energy models (or other modalities) and their attendant computation layers which execute models. While the lines between these two approaches is blurred in some sense - under the hood, many UBEM studies likely implement some form of description/translation/computation isolation - here, we hope to shift the vocabulary and organizational frameworks by more explicitly surfacing and decoupling these different layers. In so doing, the goal is to leverage the affordances of such isolation to enable the creation of more robust, detailed, and larger scale building stock energy models. Part of the motivation is to more rigorously define a framework for the interactions of GIS managers, building energy modelers, and research software engineers which can better organize the development and construction of national and global-scale building stock energy models which achieve ... (granularity? varying data availability? etc etc)</p> <p>The term semantic is chosen to emphasize the level of detail of information stored in the building description layer and re-inforce its conceptual isolation from the syntactic interpretation within the translation and computation layers. This enforces a stricter separation of concerns between the semantic building descriptions and the syntactic energy models. Rather than storing detailed energy-model information, which might often be numerical value assignments or other energy-model specific components/information, e.g. <code>Window U-Value = 2.72 W/m2K, Window SHGC=0.8</code> or <code>Infiltration rate = 0.05 m3/s/m2 exposed exterior surface area</code>, this layer is meant to capture coarser, human-readable semantic information about a building, e.g. <code>Single Pane Window</code> or <code>Leaky envelope</code>. The translation layer implemented by any particular modeling engine is responsible for converting these high-level fields into whatever form necessary to execute its computation. In so doing, this separation of concerns also allows for better separation of responsibilities which can better take advantage of the different skillsets of the various process stakeholders: GIS managers are clearly responsible for the building description layer, energy modelers are clearly responsible for defining the interpretation of fields by defining atomistic components and component selection mappings, and finally research software engineers are clearly responsible for the compilation and execution of models according to the transformations and component mappings defined by the energy modelers on top of the GIS data provided by the GIS managers. An obvious requirement of such a framework then is concise, clear interfaces between each layer: a layer must provide manifests of what information it requires, and what information it produces.</p> <ol> <li>still to include for discussion:</li> <li>allowing for probabilistic representation over semantic features</li> </ol> <p>By separating concerns, we enable the model description and computation to become decoupled in separate layers, with the obvious consequence that the model compilation and computation layer can be swapped out for different performance/cost tradeoffs or different modalities of analysis altogether. For instance, a variety of approaches can be used to achieve the desired scale of results in a reasonable amount of time: on the one hand, using high horizontal capacity and whitebox physics-based models, i.e. distributed cloud computing with large volumes of parallel nodes with low-throughput per node, or on the other hand, high vertical capacity and blackbox machine-learned models of the same function, i.e. exteremely high-throughput on relatively few GPU-equipped compute nodes. Similarly, different analysis engines can be supported from the same building-stock description, from a Bayesian model of a retrofit uptake economics analysis to an hourly heat-risk analysis which is accurate at the building scale, both consuming the same source dataset. The isolation of the building stock descriptions from the analysis engines makes it (relatively) straightforward to support these different approaches simultaneously.</p> <p>To illustrate the utility of such a framework, a case study is conducted which models approximately 2.3 million residential buildings in the state of Massachusetts while considering a variety of fields associated with each building, such as age, single-family vs multi-family, heating systems, and more. This model is then used to analyze the economic efficacy of heat-pump adoption for homeowners and illustrate how increasing the level of semantic knowledge about heating systems drastically changes the outlook for the state of Massachusetts.</p> <p>In proposing Semantic Stock Modeling, our goal is not to immediately define a completed, universal standard for how building stock models should be represented, but rather to provide a new methodological framework which building stock modeling efforts can follow to better organize stakeholders and empower large scale data exchange and analysis.</p>"},{"location":"outline/#lit-review","title":"Lit Review","text":"<ol> <li>classic ubem papers</li> <li>existing templating efforts</li> <li>similar approaches which are not tied to real buildings: resstock - highly detailed, distributions, etc etc, but can't tell u what 123 Oak st's energy use is.</li> </ol>"},{"location":"outline/#methodology","title":"Methodology","text":"<ol> <li> <p>solution: decoupling buildings from energy models</p> </li> <li> <p>maintain stricter separation of concerns between semantic building descriptions and the syntactic energy models</p> </li> <li>interpretation layers with clear interfaces compile energy models</li> <li>energy modelers escape curse of dimensionality through simpler atomistic component definitions and rule specifications</li> <li> <p>allowing for probabilistic representation over semantic features</p> </li> <li> <p>defining semantics</p> </li> <li>defining energy model components</li> <li>defining translation layers</li> <li>extensibility as new data becomes available, e.g. going from age/(sfh|mfh) to age/(sfh|mfh)/(window type)</li> <li>collapsing uncertainty</li> </ol>"},{"location":"outline/#case-study-using-ssm-to-evaluate-heat-pump-economic-efficacy-in-massachusetts","title":"Case Study: Using SSM to evaluate heat-pump economic efficacy in Massachusetts","text":"<p>Massachusetts is undertaking an ambitious statewide energy transition. As a heating-dominated climate, one of the key components of its decarbonization pathway is the electrification of heating through heat pumps, vastly reducing both site energy and source emissions. State-funded programs like MassSave provide financial incentives to homeowners to increase heat pump adoption rates. However, it is not necessarily clear that the incentive strategies, which largely do not differentiate funding levels available between any two particular homes, are being effectively deployed. To illustrate this, a model of approximately 2.5m residential homes in Massachusetts was developed with the Semantic Stock Modeling methodology. The model is used to determine the net change in dollars spent for home energy usage for each home when transitioning to a heat pump; crucially, the financial rationality of switching to a heat pump entirely depends on whether or not the home is originally heated via delivered heating oil or natural gas and the associated grid economics.</p> <p>To conduct this case study, two data sources are used: the Overture Maps Foundation Buildings database, which contains footprints and heights for every building in Massachusetts and limited building-use information, and the MassGIS Standardized Assessors' Parcel Map dataset, which contains more detailed age and parcel use data.</p>"},{"location":"outline/#semantic-stock-model-workflow","title":"Semantic Stock Model Workflow","text":"<p>Following the SSM philosophy, a sequence of transformations are described to generate the high-level semantic fields which are available to the energy modeler, and guide their component definitions. First, we will specify the datasets being used.</p> <pre><code>sources:\n  overture:\n    - geometry\n    - height\n    - primary_use\n    - secondary_use\n    - area\n  massgis:\n    - year_built\n    - parcel_use\n</code></pre> <p>Next, we specify a sequence of transformations from the raw dataset to generate the semantic fields.</p> <pre><code>computed:\n  divide:\n    source: height\n    divisor: 3.5\n    round: up\n    output: num_floors\n\n  concatenate:\n    separator: \": \"\n    columns:\n      - primary_use:\n          source: overture\n      - secondary_use:\n          source: overture\n      - parcel_use:\n          source: massgis\n    output: uses\n\n  classify:\n    source: uses\n    targets:\n      - residential single-family\n      - residential multi-family\n      - non-residential\n    output: use_class\n\n  group:\n    source: year_built\n    breakpoints:\n      values:\n        - 1975\n        - 2003\n      before: pre_\n      between: _to_\n      after: post_\n    output: age_bracket\n</code></pre> <p>Notice that the classification of the raw <code>uses</code> field into coarse categories is left as an implementation detail, which could be easily implemented with anything from regular expression pattern matching to traditional NLP techniques, embedding vector search, or LLM-driven word-association.</p> <p>Next we attach a filter, since we are only want to consider residential buildings with an area less than or equal to X sqm:</p> <pre><code>filters:\n  op: and\n  conditions:\n    - source: use_class\n      condition:\n        starts-with: residential\n    - source: area\n      condition:\n        le: x\n</code></pre> <p>Finally, we define which fields are available for use by the energy modeler:</p> <pre><code>yields:\n  area:\n    min: 0\n    max: null\n    units: sqft\n  num_floors:\n    min: 1\n    max: null\n    type: integer\n    units: floors\n  age:\n    min: 1670\n    max: 2024\n    type: integer\n    units: years\n  age_bracket:\n    categories:\n      - pre_1975\n      - 1975_to_2003\n      - post_2003\n  use_class:\n    categories:\n      - residential multi-family\n      - residential single-family\n</code></pre> <p>The energy model interpretation layer can then be represented with a straightforward component map. The component-map is used to determine how various components defined by the energy modeler will be selected and compiled in the energy model, including nested selections and value overwriting. For instance, here we see that different envelope constructions will first be selected according to whether or not the building is a single-family home or multi-family home; then the window constructions will be updated according to the age bracket as well the nested thickness of the facade construction's insulation layer. We also see that a single default space use template will be used, representing things like thermostat setpoints and schedules, while the occupant density will be directly specified according to whether or not it is a single-family or multi-family home, and the nested equipment density will be decremented according to the year built.</p> <pre><code>component-map:\n  envelope:\n    source: use_class\n    window-construction:\n      source: age_bracket\n    facade-construction:\n      insulation-layer:\n        thickness:\n          source: age_bracket\n    infiltration:\n      source: age_bracket\n\n  space_use:\n    source: default\n    occupants:\n      density:\n        assign:\n          source: use_class\n          value:\n            - residential single-family: 0.xx\n            - residential multi-family: 0.xx\n    loads:\n      source: use_class\n      epd:\n        op:\n          source: age_bracket\n          type: subtract\n          value:\n            - pre_1975: 0\n            - 1975_to_2003: 0.4\n            - post_2003: 0.8\n</code></pre> <p>TODO: update the above with actual values</p> <p>While this is not a complete description of the building energy model used in the case study, it illustrates the conceptual utility of the SSM approach: the energy modeler only needs to define a few components, and then a ruleset for how those components should be selected, combined, or mutated when compiling the energy model for each building according to the semantic fields provided. As previously mentioned, the domain-specific language illustrated here is not meant to be a final standard, but rather, just one example of how this approach can be used to clearly communicate the connection between the different layers.</p> <p>This information in conjunction with the base datasets is sufficient to construct the EnergyPlus model for each building and execute the simulations as a massively parallel job in the cloud with thousands of compute nodes.</p> <p>__TODO: discuss</p>"},{"location":"outline/#results","title":"Results","text":"<ol> <li> <p>unknowns</p> </li> <li> <p>heating system</p> </li> <li>basement status</li> <li> <p>attic status</p> </li> <li> <p>assumptions</p> </li> <li>predictions with fuel assignment unknown</li> <li>predictictions with fuel assignment unknown</li> <li>ingest data from individual homeowners</li> <li>total compute time, electricity, carbon?</li> </ol>"},{"location":"outline/#discussion","title":"Discussion","text":"<ol> <li>Future work</li> <li>illustrating different ways of incorporating distributional data</li> <li>discussing things like representing retrofit actions or costs etc</li> <li>more rigorously defining the stock description/transformation/compilation manifests/standards.</li> </ol>"},{"location":"outline/#conclusion","title":"Conclusion","text":""}]}